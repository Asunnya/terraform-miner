{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terraform AST Analysis for Mutation Testing\n",
    "This notebook demonstrates advanced semantic analysis of Terraform configurations using the TerraformAstAnalyzer class. We'll explore how to extract meaningful insights from Terraform code that can help design effective mutation operators for testing.\n",
    "1. Introduction and Setup\n",
    "The TerraformAstAnalyzer provides a way to parse Terraform files into an Abstract Syntax Tree (AST) and extract semantic information, including:\n",
    "\n",
    "Resource relationships and dependencies\n",
    "Full attribute paths and values\n",
    "Dynamic blocks and meta-arguments\n",
    "Changes between different versions of configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "sys.path.append(str(Path(__file__).parent.parent))\n",
    "from src.analysis.terraform_ast import TerraformAstAnalyzer\n",
    "from src.analysis.diff_utils import (\n",
    "    parse_patch_to_dataframe,\n",
    "    analyze_terraform_changes,\n",
    "    enrich_dataframe_with_terraform_ast\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Parsing Terraform Configuration Files\n",
    "Let's start by analyzing a simple Terraform configuration. We'll create an example file and parse it with the TerraformAstAnalyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resources found: 0 types\n"
     ]
    }
   ],
   "source": [
    "# Create a sample Terraform configuration\n",
    "sample_tf = \"\"\"\n",
    "resource \"aws_vpc\" \"main\" {\n",
    "  cidr_block = \"10.0.0.0/16\"\n",
    "  tags = {\n",
    "    Name = \"main-vpc\"\n",
    "    Environment = \"production\"\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_subnet\" \"primary\" {\n",
    "  vpc_id     = aws_vpc.main.id\n",
    "  cidr_block = \"10.0.1.0/24\"\n",
    "  availability_zone = \"us-east-1a\"\n",
    "  \n",
    "  tags = {\n",
    "    Name = \"primary-subnet\"\n",
    "  }\n",
    "}\n",
    "\n",
    "resource \"aws_security_group\" \"web\" {\n",
    "  name        = \"web-sg\"\n",
    "  description = \"Allow web traffic\"\n",
    "  vpc_id      = aws_vpc.main.id\n",
    "\n",
    "  ingress {\n",
    "    from_port   = 80\n",
    "    to_port     = 80\n",
    "    protocol    = \"tcp\"\n",
    "    cidr_blocks = [\"0.0.0.0/0\"]\n",
    "  }\n",
    "\n",
    "  ingress {\n",
    "    from_port   = 443\n",
    "    to_port     = 443\n",
    "    protocol    = \"tcp\"\n",
    "    cidr_blocks = [\"0.0.0.0/0\"]\n",
    "  }\n",
    "\n",
    "  egress {\n",
    "    from_port   = 0\n",
    "    to_port     = 0\n",
    "    protocol    = \"-1\"\n",
    "    cidr_blocks = [\"0.0.0.0/0\"]\n",
    "  }\n",
    "  \n",
    "  depends_on = [aws_vpc.main]\n",
    "}\n",
    "\n",
    "resource \"aws_instance\" \"web\" {\n",
    "  ami           = \"ami-0c55b159cbfafe1f0\"\n",
    "  instance_type = \"t2.micro\"\n",
    "  subnet_id     = aws_subnet.primary.id\n",
    "  \n",
    "  vpc_security_group_ids = [\n",
    "    aws_security_group.web.id\n",
    "  ]\n",
    "  \n",
    "  count = 2\n",
    "  \n",
    "  tags = {\n",
    "    Name = \"web-server-${count.index}\"\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Write to a temporary file\n",
    "with open(\"sample.tf\", \"w\") as f:\n",
    "    f.write(sample_tf)\n",
    "\n",
    "# Parse the file using TerraformAstAnalyzer\n",
    "analyzer = TerraformAstAnalyzer()\n",
    "ast = analyzer.parse_file(\"sample.tf\")\n",
    "\n",
    "# Display basic information about the parsed file\n",
    "print(f\"Resources found: {len(ast.get('resource', {}))} types\")\n",
    "for res_type, instances in ast.get('resource', {}).items():\n",
    "    print(f\"  {res_type}: {len(instances)} instance(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extracting Semantic Information\n",
    "Now that we've parsed the file, let's explore the semantic information we can extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes with their paths:\n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 attributes with their paths\n",
    "print(\"Attributes with their paths:\")\n",
    "for attr in analyzer.attributes[:10]:\n",
    "    print(f\"  {attr.path} = {attr.value}\")\n",
    "\n",
    "if len(analyzer.attributes) > 10:\n",
    "    print(f\"  ... and {len(analyzer.attributes) - 10} more attributes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resource references:\n"
     ]
    }
   ],
   "source": [
    "# Display all references between resources\n",
    "print(\"\\nResource references:\")\n",
    "for ref in analyzer.references:\n",
    "    print(f\"  {ref.source_path} -> {ref.target_path} (via {ref.attribute_path}, type: {ref.reference_type})\")\n",
    "\n",
    "# Visualize the dependency graph\n",
    "def visualize_dependencies(graph):\n",
    "    \"\"\"Visualize a resource dependency graph.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Use a layout that spreads nodes out\n",
    "    pos = nx.spring_layout(graph, seed=42)\n",
    "    \n",
    "    # Draw nodes with different colors based on resource type\n",
    "    node_colors = []\n",
    "    resource_types = {}\n",
    "    \n",
    "    for node in graph.nodes():\n",
    "        resource_type = node.split('.')[0] if '.' in node else node\n",
    "        if resource_type not in resource_types:\n",
    "            resource_types[resource_type] = len(resource_types)\n",
    "        node_colors.append(resource_types[resource_type])\n",
    "    \n",
    "    nx.draw_networkx_nodes(graph, pos, node_color=node_colors, cmap=plt.cm.tab10, \n",
    "                          node_size=700, alpha=0.8)\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(graph, pos, edge_color='gray', arrowsize=15, width=1.5)\n",
    "    \n",
    "    # Draw labels\n",
    "    nx.draw_networkx_labels(graph, pos, font_size=8)\n",
    "    \n",
    "    plt.title(\"Terraform Resource Dependencies\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the dependency graph if not empty\n",
    "if analyzer.dependency_graph.nodes:\n",
    "    visualize_dependencies(analyzer.dependency_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for resources with count or for_each\n",
    "for resource_type, instances in ast.get('resource', {}).items():\n",
    "    for resource_name, attrs in instances.items():\n",
    "        resource_path = f\"{resource_type}.{resource_name}\"\n",
    "        \n",
    "        count = analyzer.get_resource_count(resource_path)\n",
    "        for_each = analyzer.get_resource_for_each(resource_path)\n",
    "        \n",
    "        if count is not None:\n",
    "            print(f\"Resource {resource_path} uses count: {count}\")\n",
    "        \n",
    "        if for_each is not None:\n",
    "            print(f\"Resource {resource_path} uses for_each: {for_each}\")\n",
    "\n",
    "# Look for dynamic blocks\n",
    "dynamic_blocks = analyzer.resolve_dynamic_blocks()\n",
    "if dynamic_blocks:\n",
    "    print(\"\\nDynamic blocks found:\")\n",
    "    for resource, blocks in dynamic_blocks.items():\n",
    "        print(f\"  {resource}: {', '.join(blocks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Analyzing Changes Between Versions\n",
    "A key aspect of mutation testing is understanding changes between different versions of the same file. Let's simulate this by creating a modified version of our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Change summary:\n",
      "  Added attributes: 0\n",
      "  Removed attributes: 0\n",
      "  Modified attributes: 0\n",
      "  Resources with dependency changes: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a modified version of the sample\n",
    "modified_tf = sample_tf.replace(\n",
    "    'cidr_block = \"10.0.0.0/16\"',\n",
    "    'cidr_block = \"172.16.0.0/16\"\\n  enable_dns_support = true'\n",
    ").replace(\n",
    "    'instance_type = \"t2.micro\"',\n",
    "    'instance_type = \"t3.small\"'\n",
    ").replace(\n",
    "    'count = 2',\n",
    "    'count = 3'\n",
    ")\n",
    "\n",
    "# Write to a temporary file\n",
    "with open(\"modified.tf\", \"w\") as f:\n",
    "    f.write(modified_tf)\n",
    "\n",
    "# Analyze changes\n",
    "changes = analyze_terraform_changes(sample_tf, modified_tf)\n",
    "\n",
    "# Print summary of changes\n",
    "print(\"\\nChange summary:\")\n",
    "print(f\"  Added attributes: {len(changes['added'])}\")\n",
    "print(f\"  Removed attributes: {len(changes['removed'])}\")\n",
    "print(f\"  Modified attributes: {len(changes['modified'])}\")\n",
    "print(f\"  Resources with dependency changes: {len(changes.get('dependency_changes', []))}\")\n",
    "\n",
    "# Print added attributes\n",
    "if changes['added']:\n",
    "    print(\"\\nAdded attributes:\")\n",
    "    for item in changes['added']:\n",
    "        print(f\"  + {item['path']} = {item['value']}\")\n",
    "\n",
    "# Print removed attributes\n",
    "if changes['removed']:\n",
    "    print(\"\\nRemoved attributes:\")\n",
    "    for item in changes['removed']:\n",
    "        print(f\"  - {item['path']} = {item['value']}\")\n",
    "\n",
    "# Print modified attributes\n",
    "if changes['modified']:\n",
    "    print(\"\\nModified attributes:\")\n",
    "    for item in changes['modified']:\n",
    "        print(f\"  ~ {item['path']}: {item['old_value']} -> {item['new_value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Git Diff Fragments\n",
    "Now let's examine how to analyze git diff fragments, which is crucial for understanding real-world Terraform changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic diff DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>old_lineno</th>\n",
       "      <th>new_lineno</th>\n",
       "      <th>hunk_id</th>\n",
       "      <th>change</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>context</td>\n",
       "      <td>diff --git a/main.tf b/main.tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>context</td>\n",
       "      <td>index 1234567..abcdefg 100644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meta</td>\n",
       "      <td>--- a/main.tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>context</td>\n",
       "      <td>+++ b/main.tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>meta</td>\n",
       "      <td>@@ -10,7 +10,7 @@ resource \"aws_vpc\" \"main\" {</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>context</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>context</td>\n",
       "      <td>resource \"aws_subnet\" \"primary\" {</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>context</td>\n",
       "      <td>vpc_id     = aws_vpc.main.id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>removed</td>\n",
       "      <td>cidr_block = \"10.0.1.0/24\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>added</td>\n",
       "      <td>cidr_block = \"10.0.2.0/24\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  old_lineno  new_lineno  hunk_id   change  \\\n",
       "0       None         0.0         0.0      0.0  context   \n",
       "1       None         1.0         1.0      0.0  context   \n",
       "2  a/main.tf         NaN         NaN      NaN     meta   \n",
       "3  a/main.tf         2.0         2.0      0.0  context   \n",
       "4  a/main.tf         NaN         NaN      1.0     meta   \n",
       "5  a/main.tf        10.0        10.0      1.0  context   \n",
       "6  a/main.tf        11.0        11.0      1.0  context   \n",
       "7  a/main.tf        12.0        12.0      1.0  context   \n",
       "8  a/main.tf        13.0         NaN      1.0  removed   \n",
       "9  a/main.tf         NaN        13.0      1.0    added   \n",
       "\n",
       "                                         content  \n",
       "0                 diff --git a/main.tf b/main.tf  \n",
       "1                  index 1234567..abcdefg 100644  \n",
       "2                                  --- a/main.tf  \n",
       "3                                  +++ b/main.tf  \n",
       "4  @@ -10,7 +10,7 @@ resource \"aws_vpc\" \"main\" {  \n",
       "5                                                 \n",
       "6              resource \"aws_subnet\" \"primary\" {  \n",
       "7                   vpc_id     = aws_vpc.main.id  \n",
       "8                     cidr_block = \"10.0.1.0/24\"  \n",
       "9                     cidr_block = \"10.0.2.0/24\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enriched diff DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>old_lineno</th>\n",
       "      <th>new_lineno</th>\n",
       "      <th>hunk_id</th>\n",
       "      <th>change</th>\n",
       "      <th>content</th>\n",
       "      <th>attribute_path</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>resource_name</th>\n",
       "      <th>change_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>removed</td>\n",
       "      <td>cidr_block = \"10.0.1.0/24\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>added</td>\n",
       "      <td>cidr_block = \"10.0.2.0/24\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>added</td>\n",
       "      <td>protocol    = \"tcp\"</td>\n",
       "      <td>ingress[1].protocol</td>\n",
       "      <td>protocol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>added</td>\n",
       "      <td>cidr_blocks = [\"0.0.0.0/0\"]</td>\n",
       "      <td>ingress[1].cidr_blocks[0]</td>\n",
       "      <td>cidr_blocks[0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>added</td>\n",
       "      <td>}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>added</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>added</td>\n",
       "      <td>ingress {</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>added</td>\n",
       "      <td>from_port   = 443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a/main.tf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>added</td>\n",
       "      <td>to_port     = 443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file  old_lineno  new_lineno  hunk_id   change  \\\n",
       "8   a/main.tf        13.0         NaN      1.0  removed   \n",
       "9   a/main.tf         NaN        13.0      1.0    added   \n",
       "17  a/main.tf         NaN        28.0      2.0    added   \n",
       "18  a/main.tf         NaN        29.0      2.0    added   \n",
       "19  a/main.tf         NaN        30.0      2.0    added   \n",
       "20  a/main.tf         NaN        31.0      2.0    added   \n",
       "21  a/main.tf         NaN        32.0      2.0    added   \n",
       "22  a/main.tf         NaN        33.0      2.0    added   \n",
       "23  a/main.tf         NaN        34.0      2.0    added   \n",
       "\n",
       "                            content             attribute_path  \\\n",
       "8        cidr_block = \"10.0.1.0/24\"                        NaN   \n",
       "9        cidr_block = \"10.0.2.0/24\"                        NaN   \n",
       "17              protocol    = \"tcp\"        ingress[1].protocol   \n",
       "18      cidr_blocks = [\"0.0.0.0/0\"]  ingress[1].cidr_blocks[0]   \n",
       "19                                }                        NaN   \n",
       "20                                                         NaN   \n",
       "21                        ingress {                        NaN   \n",
       "22                from_port   = 443                        NaN   \n",
       "23                to_port     = 443                        NaN   \n",
       "\n",
       "     resource_type  resource_name change_type  \n",
       "8              NaN            NaN         NaN  \n",
       "9              NaN            NaN         NaN  \n",
       "17        protocol            NaN       added  \n",
       "18  cidr_blocks[0]            NaN       added  \n",
       "19             NaN            NaN         NaN  \n",
       "20             NaN            NaN         NaN  \n",
       "21             NaN            NaN         NaN  \n",
       "22             NaN            NaN         NaN  \n",
       "23             NaN            NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a sample git diff\n",
    "sample_diff = \"\"\"diff --git a/main.tf b/main.tf\n",
    "index 1234567..abcdefg 100644\n",
    "--- a/main.tf\n",
    "+++ b/main.tf\n",
    "@@ -10,7 +10,7 @@ resource \"aws_vpc\" \"main\" {\n",
    " \n",
    " resource \"aws_subnet\" \"primary\" {\n",
    "   vpc_id     = aws_vpc.main.id\n",
    "-  cidr_block = \"10.0.1.0/24\"\n",
    "+  cidr_block = \"10.0.2.0/24\"\n",
    "   availability_zone = \"us-east-1a\"\n",
    "   \n",
    "   tags = {\n",
    "@@ -25,6 +25,12 @@ resource \"aws_security_group\" \"web\" {\n",
    "   ingress {\n",
    "     from_port   = 80\n",
    "     to_port     = 80\n",
    "+    protocol    = \"tcp\"\n",
    "+    cidr_blocks = [\"0.0.0.0/0\"]\n",
    "+  }\n",
    "+\n",
    "+  ingress {\n",
    "+    from_port   = 443\n",
    "+    to_port     = 443\n",
    "     protocol    = \"tcp\"\n",
    "     cidr_blocks = [\"0.0.0.0/0\"]\n",
    "   }\n",
    "\"\"\"\n",
    "\n",
    "# Parse the diff to a DataFrame\n",
    "diff_df = parse_patch_to_dataframe(sample_diff)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Basic diff DataFrame:\")\n",
    "display(diff_df.head(10))\n",
    "\n",
    "# Enrich the DataFrame with Terraform semantic information\n",
    "enriched_df = enrich_dataframe_with_terraform_ast(diff_df)\n",
    "\n",
    "# Display the enriched DataFrame\n",
    "print(\"\\nEnriched diff DataFrame:\")\n",
    "display(enriched_df[enriched_df['change'].isin(['added', 'removed'])].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying Bug Patterns for Mutation Operators\n",
    "Now let's analyze some common bug patterns in Terraform configurations to guide mutation operator design:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bug Pattern: incorrect_reference ===\n",
      "Attributes:\n",
      "References:\n",
      "  No references found\n",
      "\n",
      "=== Bug Pattern: invalid_cidr ===\n",
      "Attributes:\n",
      "References:\n",
      "  No references found\n",
      "\n",
      "=== Bug Pattern: missing_required_tag ===\n",
      "Attributes:\n",
      "References:\n",
      "  No references found\n",
      "\n",
      "=== Bug Pattern: security_group_too_open ===\n",
      "Attributes:\n",
      "References:\n",
      "  No references found\n",
      "\n",
      "=== Bug Pattern: hardcoded_credentials ===\n",
      "Attributes:\n",
      "  provider[0].aws.access_key = AKIAIOSFODNN7EXAMPLE\n",
      "  provider[0].aws.secret_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n",
      "  provider[0].aws.region = us-west-2\n",
      "References:\n",
      "  No references found\n"
     ]
    }
   ],
   "source": [
    "# Create a collection of sample bug patterns\n",
    "bug_samples = {\n",
    "    \"incorrect_reference\": \"\"\"\n",
    "    resource \"aws_instance\" \"web\" {\n",
    "      ami           = \"ami-0c55b159cbfafe1f0\"\n",
    "      subnet_id     = aws_subnet.wrong.id  # Referencing non-existent resource\n",
    "    }\n",
    "    \"\"\",\n",
    "    \n",
    "    \"invalid_cidr\": \"\"\"\n",
    "    resource \"aws_vpc\" \"main\" {\n",
    "      cidr_block = \"10.0.0.0/8\"  # Too large for most applications\n",
    "    }\n",
    "    \"\"\",\n",
    "    \n",
    "    \"missing_required_tag\": \"\"\"\n",
    "    resource \"aws_instance\" \"db\" {\n",
    "      ami           = \"ami-0c55b159cbfafe1f0\"\n",
    "      instance_type = \"t2.micro\"\n",
    "      # Missing required tags\n",
    "    }\n",
    "    \"\"\",\n",
    "    \n",
    "    \"security_group_too_open\": \"\"\"\n",
    "    resource \"aws_security_group\" \"alb\" {\n",
    "      ingress {\n",
    "        protocol    = \"-1\"\n",
    "        from_port   = 0\n",
    "        to_port     = 0\n",
    "        cidr_blocks = [\"0.0.0.0/0\"]  # Too permissive\n",
    "      }\n",
    "    }\n",
    "    \"\"\",\n",
    "    \n",
    "    \"hardcoded_credentials\": \"\"\"\n",
    "    provider \"aws\" {\n",
    "      access_key = \"AKIAIOSFODNN7EXAMPLE\"\n",
    "      secret_key = \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\"\n",
    "      region     = \"us-west-2\"\n",
    "    }\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Analyze each bug pattern\n",
    "results = []\n",
    "\n",
    "for pattern_name, content in bug_samples.items():\n",
    "    analyzer = TerraformAstAnalyzer()\n",
    "    ast = analyzer.parse_hcl(content)\n",
    "    \n",
    "    # Extract attributes\n",
    "    attributes = [\n",
    "        {\"name\": attr.path, \"value\": str(attr.value)}\n",
    "        for attr in analyzer.attributes\n",
    "    ]\n",
    "    \n",
    "    # Extract references\n",
    "    references = [\n",
    "        {\"source\": ref.source_path, \"target\": ref.target_path}\n",
    "        for ref in analyzer.references\n",
    "    ]\n",
    "    \n",
    "    results.append({\n",
    "        \"pattern\": pattern_name,\n",
    "        \"content\": content,\n",
    "        \"attributes\": attributes,\n",
    "        \"references\": references\n",
    "    })\n",
    "\n",
    "# Display the results\n",
    "for result in results:\n",
    "    print(f\"\\n=== Bug Pattern: {result['pattern']} ===\")\n",
    "    print(\"Attributes:\")\n",
    "    for attr in result['attributes']:\n",
    "        print(f\"  {attr['name']} = {attr['value']}\")\n",
    "    \n",
    "    print(\"References:\")\n",
    "    if result['references']:\n",
    "        for ref in result['references']:\n",
    "            print(f\"  {ref['source']} -> {ref['target']}\")\n",
    "    else:\n",
    "        print(\"  No references found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing Mutation Operators\n",
    "Based on our analysis, we can now design mutation operators specifically for Terraform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mutation Operator: CIDR_RANGE_MUTATION ===\n",
      "Description: Mutate CIDR block ranges\n",
      "Target Pattern: cidr_block\\s*=\\s*\"([0-9\\.]+)/([0-9]+)\"\n",
      "Sample Mutations:\n",
      "  cidr_block = \"10.0.0.0/16\" -> cidr_block = \"10.0.0.0/24\"\n",
      "  cidr_block = \"10.0.0.0/24\" -> cidr_block = \"10.0.0.0/8\"\n",
      "\n",
      "=== Mutation Operator: REFERENCE_REPLACEMENT ===\n",
      "Description: Replace resource references with incorrect ones\n",
      "Target Pattern: (\\w+)_id\\s*=\\s*([a-zA-Z0-9_]+)\\.([a-zA-Z0-9_]+)\\.id\n",
      "Sample Mutations:\n",
      "  subnet_id = aws_subnet.primary.id -> subnet_id = aws_subnet.secondary.id\n",
      "  vpc_id = aws_vpc.main.id -> vpc_id = aws_vpc.wrong.id\n",
      "\n",
      "=== Mutation Operator: COUNT_MODIFICATION ===\n",
      "Description: Modify count parameter\n",
      "Target Pattern: count\\s*=\\s*([0-9]+)\n",
      "Sample Mutations:\n",
      "  count = 2 -> count = 1\n",
      "  count = 2 -> count = 0\n",
      "  count = 2 -> count = 3\n",
      "\n",
      "=== Mutation Operator: SECURITY_GROUP_RULE_MUTATION ===\n",
      "Description: Mutate security group rules\n",
      "Target Pattern: (from_port|to_port)\\s*=\\s*([0-9]+)\n",
      "Sample Mutations:\n",
      "  from_port = 80 -> from_port = 0\n",
      "  to_port = 443 -> to_port = 65535\n",
      "\n",
      "=== Mutation Operator: TAG_REMOVAL ===\n",
      "Description: Remove required tags\n",
      "Target Pattern: tags\\s*=\\s*\\{([^}]*)\\}\n",
      "Sample Mutations:\n",
      "  tags = { Name = \"example\" } -> tags = {}\n",
      "  tags = { Name = \"example\", Environment = \"prod\" } -> tags = { Name = \"example\" }\n"
     ]
    }
   ],
   "source": [
    "# Define mutation operator templates\n",
    "mutation_operators = [\n",
    "    {\n",
    "        \"name\": \"CIDR_RANGE_MUTATION\",\n",
    "        \"description\": \"Mutate CIDR block ranges\",\n",
    "        \"target_pattern\": r'cidr_block\\s*=\\s*\"([0-9\\.]+)/([0-9]+)\"',\n",
    "        \"mutation_logic\": \"Modify the subnet mask to be wider or narrower\",\n",
    "        \"sample_mutations\": [\n",
    "            'cidr_block = \"10.0.0.0/16\" -> cidr_block = \"10.0.0.0/24\"',\n",
    "            'cidr_block = \"10.0.0.0/24\" -> cidr_block = \"10.0.0.0/8\"'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"REFERENCE_REPLACEMENT\",\n",
    "        \"description\": \"Replace resource references with incorrect ones\",\n",
    "        \"target_pattern\": r'(\\w+)_id\\s*=\\s*([a-zA-Z0-9_]+)\\.([a-zA-Z0-9_]+)\\.id',\n",
    "        \"mutation_logic\": \"Replace the reference with another resource of similar type\",\n",
    "        \"sample_mutations\": [\n",
    "            'subnet_id = aws_subnet.primary.id -> subnet_id = aws_subnet.secondary.id',\n",
    "            'vpc_id = aws_vpc.main.id -> vpc_id = aws_vpc.wrong.id'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"COUNT_MODIFICATION\",\n",
    "        \"description\": \"Modify count parameter\",\n",
    "        \"target_pattern\": r'count\\s*=\\s*([0-9]+)',\n",
    "        \"mutation_logic\": \"Increase, decrease, or zero out the count value\",\n",
    "        \"sample_mutations\": [\n",
    "            'count = 2 -> count = 1',\n",
    "            'count = 2 -> count = 0',\n",
    "            'count = 2 -> count = 3'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SECURITY_GROUP_RULE_MUTATION\",\n",
    "        \"description\": \"Mutate security group rules\",\n",
    "        \"target_pattern\": r'(from_port|to_port)\\s*=\\s*([0-9]+)',\n",
    "        \"mutation_logic\": \"Modify port ranges to introduce security vulnerabilities\",\n",
    "        \"sample_mutations\": [\n",
    "            'from_port = 80 -> from_port = 0',\n",
    "            'to_port = 443 -> to_port = 65535'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"TAG_REMOVAL\",\n",
    "        \"description\": \"Remove required tags\",\n",
    "        \"target_pattern\": r'tags\\s*=\\s*\\{([^}]*)\\}',\n",
    "        \"mutation_logic\": \"Remove or modify tags that might be required by policy\",\n",
    "        \"sample_mutations\": [\n",
    "            'tags = { Name = \"example\" } -> tags = {}',\n",
    "            'tags = { Name = \"example\", Environment = \"prod\" } -> tags = { Name = \"example\" }'\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Display the mutation operators\n",
    "for op in mutation_operators:\n",
    "    print(f\"\\n=== Mutation Operator: {op['name']} ===\")\n",
    "    print(f\"Description: {op['description']}\")\n",
    "    print(f\"Target Pattern: {op['target_pattern']}\")\n",
    "    print(\"Sample Mutations:\")\n",
    "    for mutation in op['sample_mutations']:\n",
    "        print(f\"  {mutation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a Simple Mutation Generator\n",
    "Finally, let's implement a simple mutation generator for Terraform files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Test the mutation generator on our sample\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):  \u001b[38;5;66;03m# Generate 3 different mutations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     op = \u001b[43mrandom\u001b[49m.choice(mutation_operators)\n\u001b[32m     57\u001b[39m     mutated, desc = apply_mutation(sample_tf, op)\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mutated:\n",
      "\u001b[31mNameError\u001b[39m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "def apply_mutation(content, operator):\n",
    "    \"\"\"Apply a mutation operator to Terraform content.\"\"\"\n",
    "    import random\n",
    "    \n",
    "    pattern = re.compile(operator[\"target_pattern\"])\n",
    "    matches = list(pattern.finditer(content))\n",
    "    \n",
    "    if not matches:\n",
    "        return None, \"No matches found for this operator\"\n",
    "    \n",
    "    # Choose a random match to mutate\n",
    "    match = random.choice(matches)\n",
    "    \n",
    "    # Apply basic mutations based on the operator type\n",
    "    if operator[\"name\"] == \"CIDR_RANGE_MUTATION\":\n",
    "        network, mask = match.groups()\n",
    "        mask = int(mask)\n",
    "        new_mask = max(8, mask - 8) if random.random() < 0.5 else min(30, mask + 8)\n",
    "        new_content = content[:match.start()] + f'cidr_block = \"{network}/{new_mask}\"' + content[match.end():]\n",
    "        mutation_desc = f'Changed CIDR mask from /{mask} to /{new_mask}'\n",
    "    \n",
    "    elif operator[\"name\"] == \"COUNT_MODIFICATION\":\n",
    "        count = int(match.group(1))\n",
    "        new_count = max(0, count - 1) if count > 0 and random.random() < 0.5 else count + 1\n",
    "        new_content = content[:match.start()] + f'count = {new_count}' + content[match.end():]\n",
    "        mutation_desc = f'Changed count from {count} to {new_count}'\n",
    "    \n",
    "    elif operator[\"name\"] == \"SECURITY_GROUP_RULE_MUTATION\":\n",
    "        port_type, port = match.groups()\n",
    "        if port_type == \"from_port\":\n",
    "            new_port = 0  # Open up the lower bound\n",
    "        else:  # to_port\n",
    "            new_port = 65535  # Open up the upper bound\n",
    "        \n",
    "        new_content = content[:match.start()] + f'{port_type} = {new_port}' + content[match.end():]\n",
    "        mutation_desc = f'Changed {port_type} from {port} to {new_port}'\n",
    "    \n",
    "    elif operator[\"name\"] == \"TAG_REMOVAL\":\n",
    "        tags_content = match.group(1)\n",
    "        new_content = content[:match.start()] + 'tags = {}' + content[match.end():]\n",
    "        mutation_desc = f'Removed all tags'\n",
    "    \n",
    "    elif operator[\"name\"] == \"REFERENCE_REPLACEMENT\":\n",
    "        resource_type, resource_name = match.group(2), match.group(3)\n",
    "        new_name = f\"{resource_name}_wrong\"\n",
    "        new_content = content[:match.start(2)] + resource_type + content[match.end(2):match.start(3)] + new_name + content[match.end(3):]\n",
    "        mutation_desc = f'Changed reference from {resource_type}.{resource_name} to {resource_type}.{new_name}'\n",
    "    \n",
    "    else:\n",
    "        return None, \"Unsupported operator\"\n",
    "    \n",
    "    return new_content, mutation_desc\n",
    "\n",
    "# Test the mutation generator on our sample\n",
    "for _ in range(3):  # Generate 3 different mutations\n",
    "    op = random.choice(mutation_operators)\n",
    "    mutated, desc = apply_mutation(sample_tf, op)\n",
    "    \n",
    "    if mutated:\n",
    "        print(f\"\\n=== Applied Mutation: {op['name']} ===\")\n",
    "        print(f\"Description: {desc}\")\n",
    "        \n",
    "        # Show diff\n",
    "        from difflib import unified_diff\n",
    "        diff = '\\n'.join(unified_diff(\n",
    "            sample_tf.splitlines(),\n",
    "            mutated.splitlines(),\n",
    "            fromfile='original.tf',\n",
    "            tofile='mutated.tf',\n",
    "            lineterm=''\n",
    "        ))\n",
    "        \n",
    "        print(\"\\nDiff:\")\n",
    "        print(diff)\n",
    "        \n",
    "        # Analyze if the mutation introduces a semantic change\n",
    "        changes = analyze_terraform_changes(sample_tf, mutated)\n",
    "        \n",
    "        print(\"\\nSemantic Changes:\")\n",
    "        if changes['modified']:\n",
    "            for item in changes['modified']:\n",
    "                print(f\"  ~ {item['path']}: {item['old_value']} -> {item['new_value']}\")\n",
    "        else:\n",
    "            print(\"  No semantic changes detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Conclusion and Next Steps\n",
    "In this notebook, we've explored how to use the TerraformAstAnalyzer for advanced semantic analysis of Terraform configurations. This approach provides several key advantages for mutation testing:\n",
    "\n",
    "Precise Mutations: By understanding the AST, we can create mutations that are syntactically valid and semantically meaningful.\n",
    "Resource Awareness: We can target specific resources and their dependencies.\n",
    "Real-world Bug Patterns: We can base mutations on common bug patterns.\n",
    "\n",
    "Next steps for improving the mutation testing framework:\n",
    "\n",
    "Implement a full suite of mutation operators based on real-world bug patterns\n",
    "Create a testing framework to measure the effectiveness of mutations\n",
    "Integrate with CI/CD pipelines for continuous validation\n",
    "Add coverage analysis to determine which parts of the infrastructure are tested\n",
    "Prioritize mutations based on impact analysis\n",
    "\n",
    "This approach will lead to more effective Infrastructure as Code testing and higher quality Terraform configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
